"""
ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æä¸»æ¥å£
ç»Ÿä¸€è°ƒç”¨å„ä¸ªæ•°æ®æºï¼Œæä¾›å®Œæ•´çš„æƒ…ç»ªåˆ†æç»“æœ
"""

import asyncio
from typing import Dict, List, Optional
from datetime import datetime
import logging

from .web_scraper import WebScraper
from .data_processor import DataProcessor
from .sources import (
    SinaFinanceScraper,
    EastMoneyScraper
)

logger = logging.getLogger(__name__)


class SocialSentimentAnalyzer:
    """ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æå™¨"""
    
    def __init__(self):
        self.scraper = WebScraper()
        self.processor = DataProcessor()
        
        # åˆå§‹åŒ–å„ä¸ªæ•°æ®æº
        self.sources = {
            'sina_finance': SinaFinanceScraper(self.scraper),
            'eastmoney': EastMoneyScraper(self.scraper)
        }
        
        # æ•°æ®æºæƒé‡é…ç½®
        self.source_weights = {
            'sina_finance': 0.40,
            'eastmoney': 0.60
        }
        
        # æ¯ä¸ªæ•°æ®æºçš„è¯„è®ºæ•°é‡åˆ†é…
        self.source_limits = {
            'sina_finance': 40,
            'eastmoney': 60
        }
    
    def get_stock_social_sentiment(self, stock_code: str, total_limit: int = 100) -> Dict:
        """
        è·å–è‚¡ç¥¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç  (å¦‚: 300663)
            total_limit: æ€»è¯„è®ºæ•°é‡é™åˆ¶
            
        Returns:
            å®Œæ•´çš„æƒ…ç»ªåˆ†æç»“æœ
        """
        logger.info(f"å¼€å§‹è·å–è‚¡ç¥¨ {stock_code} çš„ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®")
        
        # æ”¶é›†æ‰€æœ‰è¯„è®º
        all_comments = []
        source_results = {}
        
        # ä»å„ä¸ªæ•°æ®æºè·å–è¯„è®º
        for source_name, source_scraper in self.sources.items():
            try:
                logger.info(f"æ­£åœ¨ä» {source_name} è·å–æ•°æ®...")
                
                # è®¡ç®—è¯¥æ•°æ®æºçš„è¯„è®ºæ•°é‡é™åˆ¶
                source_limit = min(
                    self.source_limits.get(source_name, 20),
                    int(total_limit * self.source_weights.get(source_name, 0.2))
                )
                
                # è·å–è¯„è®º
                comments = source_scraper.get_stock_comments(stock_code, source_limit)
                
                if comments:
                    all_comments.extend(comments)
                    source_results[source_name] = {
                        'count': len(comments),
                        'success': True
                    }
                    logger.info(f"âœ… {source_name} è·å–åˆ° {len(comments)} æ¡è¯„è®º")
                else:
                    source_results[source_name] = {
                        'count': 0,
                        'success': False,
                        'error': 'æœªè·å–åˆ°æ•°æ®'
                    }
                    logger.warning(f"âš ï¸ {source_name} æœªè·å–åˆ°è¯„è®º")
                    
            except Exception as e:
                source_results[source_name] = {
                    'count': 0,
                    'success': False,
                    'error': str(e)
                }
                logger.error(f"âŒ {source_name} è·å–å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆæ•°æ®
        if not all_comments:
            logger.warning(f"æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆçš„ç¤¾äº¤åª’ä½“æ•°æ®: {stock_code}")
            return self._generate_empty_result(stock_code, source_results)
        
        logger.info(f"æ€»å…±è·å–åˆ° {len(all_comments)} æ¡åŸå§‹è¯„è®º")
        
        # å¤„ç†å’Œè¿‡æ»¤è¯„è®º
        processed_comments = self.processor.process_comments(all_comments)
        
        if not processed_comments:
            logger.warning(f"æ‰€æœ‰è¯„è®ºéƒ½è¢«è¿‡æ»¤ï¼Œæ— æœ‰æ•ˆæ•°æ®: {stock_code}")
            return self._generate_empty_result(stock_code, source_results)
        
        # èšåˆæƒ…ç»ªåˆ†æ
        sentiment_analysis = self.processor.aggregate_sentiment(processed_comments)
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        result = self._generate_final_result(
            stock_code, 
            processed_comments, 
            sentiment_analysis, 
            source_results
        )
        
        logger.info(f"âœ… å®Œæˆè‚¡ç¥¨ {stock_code} çš„æƒ…ç»ªåˆ†æ")
        return result
    
    def _generate_empty_result(self, stock_code: str, source_results: Dict) -> Dict:
        """ç”Ÿæˆç©ºç»“æœ"""
        return {
            'stock_code': stock_code,
            'success': False,
            'error': 'æœªè·å–åˆ°æœ‰æ•ˆçš„ç¤¾äº¤åª’ä½“æ•°æ®',
            'timestamp': datetime.now().isoformat(),
            'data_sources': source_results,
            'sentiment_analysis': {
                'total_comments': 0,
                'average_sentiment': 0.0,
                'positive_ratio': 0.0,
                'negative_ratio': 0.0,
                'neutral_ratio': 0.0
            },
            'summary': f"ç”±äºæ•°æ®è·å–é™åˆ¶ï¼Œæ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å®æ—¶ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®ã€‚å»ºè®®å…³æ³¨å®˜æ–¹è´¢ç»åª’ä½“æŠ¥é“å’ŒåŸºæœ¬é¢åˆ†æã€‚"
        }
    
    def _generate_final_result(self, stock_code: str, comments: List[Dict], 
                             sentiment_analysis: Dict, source_results: Dict) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆåˆ†æç»“æœ"""
        
        # è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°
        data_quality_score = self._calculate_data_quality(comments, source_results)
        
        # ç”Ÿæˆæƒ…ç»ªæ€»ç»“
        sentiment_summary = self._generate_sentiment_summary(sentiment_analysis, stock_code)
        
        # æå–å…³é”®è§‚ç‚¹
        key_opinions = self._extract_key_opinions(comments)
        
        # è®¡ç®—æƒ…ç»ªè¶‹åŠ¿
        sentiment_trend = self._analyze_sentiment_trend(comments)
        
        return {
            'stock_code': stock_code,
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'data_quality_score': data_quality_score,
            'data_sources': source_results,
            'sentiment_analysis': sentiment_analysis,
            'sentiment_summary': sentiment_summary,
            'key_opinions': key_opinions,
            'sentiment_trend': sentiment_trend,
            'raw_comments_count': len(comments),
            'analysis_period': 'å®æ—¶æ•°æ®',
            'confidence_level': self._calculate_confidence_level(data_quality_score, len(comments))
        }
    
    def _calculate_data_quality(self, comments: List[Dict], source_results: Dict) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°"""
        if not comments:
            return 0.0
        
        # åŸºç¡€åˆ†æ•°ï¼šåŸºäºè¯„è®ºæ•°é‡
        comment_score = min(len(comments) / 50, 1.0) * 0.4
        
        # æ•°æ®æºå¤šæ ·æ€§åˆ†æ•°
        successful_sources = sum(1 for result in source_results.values() if result['success'])
        diversity_score = (successful_sources / len(self.sources)) * 0.3
        
        # å†…å®¹è´¨é‡åˆ†æ•°ï¼šåŸºäºå¹³å‡å†…å®¹é•¿åº¦å’Œæƒ…ç»ªå…³é”®è¯
        avg_content_length = sum(len(c['content']) for c in comments) / len(comments)
        content_score = min(avg_content_length / 100, 1.0) * 0.2
        
        # äº’åŠ¨è´¨é‡åˆ†æ•°ï¼šåŸºäºç‚¹èµå’Œå›å¤
        total_interactions = sum(c.get('likes', 0) + c.get('replies', 0) for c in comments)
        interaction_score = min(total_interactions / (len(comments) * 5), 1.0) * 0.1
        
        total_score = comment_score + diversity_score + content_score + interaction_score
        return round(total_score, 2)
    
    def _generate_sentiment_summary(self, sentiment_analysis: Dict, stock_code: str) -> str:
        """ç”Ÿæˆæƒ…ç»ªåˆ†ææ€»ç»“"""
        total_comments = sentiment_analysis['total_comments']
        avg_sentiment = sentiment_analysis['average_sentiment']
        positive_ratio = sentiment_analysis['positive_ratio']
        negative_ratio = sentiment_analysis['negative_ratio']
        
        # åˆ¤æ–­æ•´ä½“æƒ…ç»ªå€¾å‘
        if avg_sentiment > 0.2:
            sentiment_label = "åä¹è§‚"
        elif avg_sentiment < -0.2:
            sentiment_label = "åæ‚²è§‚"
        else:
            sentiment_label = "ä¸­æ€§"
        
        # ç”Ÿæˆæ€»ç»“
        summary = f"""
åŸºäº {total_comments} æ¡çœŸå®ç¤¾äº¤åª’ä½“è¯„è®ºçš„åˆ†æï¼Œ{stock_code} çš„æŠ•èµ„è€…æƒ…ç»ªå‘ˆç° {sentiment_label} æ€åŠ¿ã€‚

ğŸ“Š æƒ…ç»ªåˆ†å¸ƒï¼š
â€¢ æ­£é¢æƒ…ç»ªï¼š{positive_ratio:.1%} 
â€¢ è´Ÿé¢æƒ…ç»ªï¼š{negative_ratio:.1%}
â€¢ ä¸­æ€§è§‚ç‚¹ï¼š{sentiment_analysis['neutral_ratio']:.1%}

ğŸ’­ æƒ…ç»ªç‰¹å¾ï¼š
"""
        
        # æ·»åŠ å…³é”®è¯åˆ†æ
        top_positive = sentiment_analysis.get('top_positive_keywords', [])
        top_negative = sentiment_analysis.get('top_negative_keywords', [])
        
        if top_positive:
            pos_keywords = [kw[0] for kw in top_positive[:3]]
            summary += f"â€¢ é«˜é¢‘æ­£é¢è¯æ±‡ï¼š{', '.join(pos_keywords)}\n"
            
        if top_negative:
            neg_keywords = [kw[0] for kw in top_negative[:3]]
            summary += f"â€¢ é«˜é¢‘è´Ÿé¢è¯æ±‡ï¼š{', '.join(neg_keywords)}\n"
        
        return summary.strip()
    
    def _extract_key_opinions(self, comments: List[Dict], limit: int = 5) -> List[Dict]:
        """æå–å…³é”®è§‚ç‚¹"""
        # æŒ‰ç‚¹èµæ•°å’Œå†…å®¹é•¿åº¦æ’åº
        sorted_comments = sorted(
            comments, 
            key=lambda x: (x.get('likes', 0) * 2 + len(x['content']) / 10), 
            reverse=True
        )
        
        key_opinions = []
        for comment in sorted_comments[:limit]:
            opinion = {
                'content': comment['content'][:200] + ('...' if len(comment['content']) > 200 else ''),
                'sentiment_score': comment['sentiment_score'],
                'likes': comment.get('likes', 0),
                'source': comment.get('source', ''),
                'author': comment.get('author', 'åŒ¿å')
            }
            key_opinions.append(opinion)
            
        return key_opinions
    
    def _analyze_sentiment_trend(self, comments: List[Dict]) -> Dict:
        """åˆ†ææƒ…ç»ªè¶‹åŠ¿"""
        if not comments:
            return {'trend': 'unknown', 'description': 'æ•°æ®ä¸è¶³'}
        
        # ç®€å•çš„è¶‹åŠ¿åˆ†æï¼šæ¯”è¾ƒå‰åä¸¤éƒ¨åˆ†è¯„è®ºçš„æƒ…ç»ª
        mid_point = len(comments) // 2
        if mid_point < 5:
            return {'trend': 'stable', 'description': 'æ•°æ®é‡è¾ƒå°‘ï¼Œè¶‹åŠ¿ä¸æ˜æ˜¾'}
        
        early_comments = comments[:mid_point]
        recent_comments = comments[mid_point:]
        
        early_sentiment = sum(c['sentiment_score'] for c in early_comments) / len(early_comments)
        recent_sentiment = sum(c['sentiment_score'] for c in recent_comments) / len(recent_comments)
        
        sentiment_change = recent_sentiment - early_sentiment
        
        if sentiment_change > 0.1:
            trend = 'improving'
            description = 'æŠ•èµ„è€…æƒ…ç»ªå‘ˆç°æ”¹å–„è¶‹åŠ¿'
        elif sentiment_change < -0.1:
            trend = 'declining'
            description = 'æŠ•èµ„è€…æƒ…ç»ªå‘ˆç°ä¸‹é™è¶‹åŠ¿'
        else:
            trend = 'stable'
            description = 'æŠ•èµ„è€…æƒ…ç»ªç›¸å¯¹ç¨³å®š'
        
        return {
            'trend': trend,
            'description': description,
            'change_magnitude': round(sentiment_change, 3),
            'early_sentiment': round(early_sentiment, 3),
            'recent_sentiment': round(recent_sentiment, 3)
        }
    
    def _calculate_confidence_level(self, data_quality_score: float, comment_count: int) -> str:
        """è®¡ç®—ç½®ä¿¡åº¦ç­‰çº§"""
        if data_quality_score >= 0.7 and comment_count >= 30:
            return 'é«˜'
        elif data_quality_score >= 0.5 and comment_count >= 15:
            return 'ä¸­'
        else:
            return 'ä½'
    
    def close(self):
        """å…³é—­èµ„æº"""
        self.scraper.close()


# å…¨å±€å®ä¾‹
_analyzer = None

def get_stock_social_sentiment(stock_code: str, total_limit: int = 100) -> Dict:
    """
    è·å–è‚¡ç¥¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æï¼ˆåŒæ­¥æ¥å£ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç  (å¦‚: 300663)
        total_limit: æ€»è¯„è®ºæ•°é‡é™åˆ¶
        
    Returns:
        å®Œæ•´çš„æƒ…ç»ªåˆ†æç»“æœ
    """
    global _analyzer
    
    if _analyzer is None:
        _analyzer = SocialSentimentAnalyzer()
    
    try:
        return _analyzer.get_stock_social_sentiment(stock_code, total_limit)
    except Exception as e:
        logger.error(f"è·å–ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æå¤±è´¥: {stock_code}, é”™è¯¯: {e}")
        return {
            'stock_code': stock_code,
            'success': False,
            'error': f'åˆ†æå¤±è´¥: {str(e)}',
            'timestamp': datetime.now().isoformat(),
            'summary': f'ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•å®Œæˆè‚¡ç¥¨ {stock_code} çš„ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æã€‚'
        }